{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1-final"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.9.1 64-bit",
      "metadata": {
        "interpreter": {
          "hash": "799275936fb7c37caa15961302e1f6bc5b6f09e92bdf39e5acfe019a9d46a476"
        }
      }
    },
    "colab": {
      "name": "dry_bean_tunning.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dvIz-1A6p_l"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense\n",
        "from keras.optimizers import SGD\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_l1IvTAd6p_u"
      },
      "source": [
        "#Carregando o dataset\n",
        "df = pd.read_excel(\"https://raw.githubusercontent.com/irvin-s/smd_project/main/dataset/dry_bean_dataset.xls\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWe9myuZ6p_v"
      },
      "source": [
        "#atribuindo os labes para a classe reposta\n",
        "labels = [\"Barbunya\", \"Bombay\", \"Cali\", \"Dermason\", \"Horoz\", \"Seker\", \"Sira\"]\n",
        "\n",
        "#Dividindo a base em treino e teste\n",
        "X = df.drop(\"Class\", axis=1)\n",
        "y = df[\"Class\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.33, random_state=123)\n",
        "\n",
        "#Normalizando os dados\n",
        "ss = StandardScaler()\n",
        "X_train_norm = ss.fit_transform(X_train)\n",
        "X_test_norm = ss.fit_transform(X_test)\n",
        "\n",
        "#Transformando a variável cartegorica em binária\n",
        "labelencoder = LabelEncoder()\n",
        "y_train_bin = labelencoder.fit_transform(y_train)\n",
        "y_test_bin = labelencoder.fit_transform(y_test)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3LA8cqW6p_v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce25217f-bbbc-4615-f40e-a52aa9c5c8f9"
      },
      "source": [
        "#Aplicando o modelo KNN\n",
        "\n",
        "#Definindo o valor de vizinhos\n",
        "classifier = KNeighborsClassifier(n_neighbors=15)\n",
        "\n",
        "#Treinar o modelo, com os dados de treinamento\n",
        "classifier.fit(X_train_norm, y_train_bin)\n",
        "\n",
        "#Prever os valores de y com dos dados de X_test\n",
        "y_pred = classifier.predict(X_test_norm)\n",
        "\n",
        "# Imprimindo a matriz confusa\n",
        "print(\"Matriz Confusa KNN: \")\n",
        "print(confusion_matrix(y_test_bin, y_pred), \"\\n\")  \n",
        "\n",
        "# Imprimindo o relatório de classificação\n",
        "print(\"Relatório de classificação KNN: \\n\", classification_report(y_test_bin, y_pred, target_names=labels))  \n",
        "\n",
        "# Imprimindo o quão acurado foi o modelo\n",
        "acu_knn = accuracy_score(y_test_bin, y_pred) * 100\n",
        "print(\"Acurácia KNN: {:.2f}%\".format(acu_knn))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Matriz Confusa KNN: \n",
            "[[ 384    0   34    0    2    3   13]\n",
            " [   0  171    0    0    0    0    0]\n",
            " [  11    0  507    0    5    2    7]\n",
            " [   0    0    0 1064    0   12   68]\n",
            " [   0    0   14    2  620    0   18]\n",
            " [   2    0    0   19    1  628   24]\n",
            " [   1    0    0   93    9    6  772]] \n",
            "\n",
            "Relatório de classificação KNN: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    Barbunya       0.96      0.88      0.92       436\n",
            "      Bombay       1.00      1.00      1.00       171\n",
            "        Cali       0.91      0.95      0.93       532\n",
            "    Dermason       0.90      0.93      0.92      1144\n",
            "       Horoz       0.97      0.95      0.96       654\n",
            "       Seker       0.96      0.93      0.95       674\n",
            "        Sira       0.86      0.88      0.87       881\n",
            "\n",
            "    accuracy                           0.92      4492\n",
            "   macro avg       0.94      0.93      0.93      4492\n",
            "weighted avg       0.92      0.92      0.92      4492\n",
            "\n",
            "Acurácia KNN: 92.30%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2bfgfEB6p_w"
      },
      "source": [
        "#Aplicando a Árvore de decisão\n",
        "\n",
        "#Instanciando o modelo\n",
        "model = DecisionTreeClassifier()\n",
        "\n",
        "# Treinar o modelo\n",
        "model.fit(X_train, y_train_bin)\n",
        "\n",
        "# Aplicar o modelo ao treinamento e ao teste\n",
        "predicted_test_y = model.predict(X_test)\n",
        "\n",
        "predicted_train_y = model.predict(X_train)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwV9XKgP6p_x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97dbf348-07cd-41cd-e6e7-530a24c29ed3"
      },
      "source": [
        "# Imprimindo a matriz confusa\n",
        "print(\"Matriz Confusa Decision Tree: \")\n",
        "print(confusion_matrix(y_test_bin, predicted_test_y), \"\\n\")  \n",
        "\n",
        "# Imprimindo o relatório de classificação\n",
        "print(\"Relatório de classificação Decision Tree: \\n\", classification_report(y_test_bin, predicted_test_y, target_names=labels)) \n",
        "\n",
        "#Imprimindo a acurácia do modelo\n",
        "accuracy_dt = accuracy_score(y_test_bin, predicted_test_y) * 100\n",
        "print(\"Acurácia Decision Tree: {:.2f}%.\".format(accuracy_dt))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Matriz Confusa Decision Tree: \n",
            "[[ 380    0   35    0    7    4   10]\n",
            " [   1  170    0    0    0    0    0]\n",
            " [  28    0  486    0   11    2    5]\n",
            " [   0    0    0 1037    6   17   84]\n",
            " [   1    0   14    4  610    0   25]\n",
            " [   6    0    1   27    0  616   24]\n",
            " [   7    0    2   96   24   10  742]] \n",
            "\n",
            "Relatório de classificação Decision Tree: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    Barbunya       0.90      0.87      0.88       436\n",
            "      Bombay       1.00      0.99      1.00       171\n",
            "        Cali       0.90      0.91      0.91       532\n",
            "    Dermason       0.89      0.91      0.90      1144\n",
            "       Horoz       0.93      0.93      0.93       654\n",
            "       Seker       0.95      0.91      0.93       674\n",
            "        Sira       0.83      0.84      0.84       881\n",
            "\n",
            "    accuracy                           0.90      4492\n",
            "   macro avg       0.91      0.91      0.91      4492\n",
            "weighted avg       0.90      0.90      0.90      4492\n",
            "\n",
            "Acurácia Decision Tree: 89.96%.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWM5MLyt6p_x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2671c822-056e-41e2-d7cb-85ce64444a7a"
      },
      "source": [
        "#Aplicando a Random Forest\n",
        "\n",
        "#Instanciando o modelo\n",
        "rf = RandomForestClassifier(90, max_depth=10, random_state=42)\n",
        "rf.fit(X_train,y_train_bin)\n",
        "\n",
        "#Aplicando o modelo\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "\n",
        "# Imprimindo a matriz confusa\n",
        "print(\"Matriz Confusa Random Forest: \")\n",
        "print(confusion_matrix(y_test_bin, y_pred_rf), \"\\n\")  \n",
        "\n",
        "# Imprimindo o relatório de classificação\n",
        "print(\"Relatório de classificação Random Forest: \\n\", classification_report(y_test_bin, y_pred_rf, target_names=labels)) \n",
        "\n",
        "#Imprimindo a acurácia do modelo\n",
        "accuracy_rf = accuracy_score(y_test_bin, y_pred_rf) * 100\n",
        "print(\"Acurácia Random Forest: {:.2f}%.\".format(accuracy_rf))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Matriz Confusa Random Forest: \n",
            "[[ 381    0   36    0    4    3   12]\n",
            " [   0  171    0    0    0    0    0]\n",
            " [  13    0  505    0    5    2    7]\n",
            " [   0    0    0 1080    0   10   54]\n",
            " [   0    0   15    2  621    0   16]\n",
            " [   2    0    0   25    0  627   20]\n",
            " [   2    0    1   94   15    8  761]] \n",
            "\n",
            "Relatório de classificação Random Forest: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    Barbunya       0.96      0.87      0.91       436\n",
            "      Bombay       1.00      1.00      1.00       171\n",
            "        Cali       0.91      0.95      0.93       532\n",
            "    Dermason       0.90      0.94      0.92      1144\n",
            "       Horoz       0.96      0.95      0.96       654\n",
            "       Seker       0.96      0.93      0.95       674\n",
            "        Sira       0.87      0.86      0.87       881\n",
            "\n",
            "    accuracy                           0.92      4492\n",
            "   macro avg       0.94      0.93      0.93      4492\n",
            "weighted avg       0.92      0.92      0.92      4492\n",
            "\n",
            "Acurácia Random Forest: 92.30%.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwxVsj3h6p_y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f22f67b5-8592-49f6-b2fe-3dd593dfefa9"
      },
      "source": [
        "#Aplicando a Rede Neural MLP\n",
        "\n",
        "#Instanciado o modelo\n",
        "modelNN = Sequential()\n",
        "modelNN.add(Dense(50, input_dim=16, activation='relu'))\n",
        "modelNN.add(Dense(7, activation='softmax'))\n",
        "modelNN.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "#Vetorizar a classe resposta\n",
        "lb = LabelBinarizer()\n",
        "y_train_vet = lb.fit_transform(y_train)\n",
        "y_test_vet = lb.fit_transform(y_test)\n",
        "\n",
        "#Realizando o treinamento\n",
        "H = modelNN.fit(X_train_norm, y_train_vet, batch_size=128, epochs=300, verbose=0, validation_data=(X_test_norm, y_test_vet))\n",
        "\n",
        "#Avalidando a Rede Neural \n",
        "predictions = modelNN.predict(X_test_norm, batch_size=128)\n",
        "\n",
        "# Imprimindo a matriz confusa\n",
        "print(\"Matriz Confusa Rede Neural MLP: \")\n",
        "print(confusion_matrix(y_test_vet.argmax(axis=1), predictions.argmax(axis=1)), \"\\n\")  \n",
        "\n",
        "# Imprimindo o relatório de classificação\n",
        "print(\"Relatório de classificação Rede Neural MLP: \\n\", classification_report(y_test_vet.argmax(axis=1), predictions.argmax(axis=1), target_names=labels, zero_division=0))\n",
        "\n",
        "#Imprimindo a acurácia do modelo\n",
        "accuracy_nn = accuracy_score(y_test_vet.argmax(axis=1), predictions.argmax(axis=1)) * 100\n",
        "print(\"Acurácia Rede Neural MLP: {:.2f}%.\".format(accuracy_nn))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Matriz Confusa Rede Neural MLP: \n",
            "[[ 393    0   26    0    4    4    9]\n",
            " [   0  171    0    0    0    0    0]\n",
            " [  16    0  501    0    5    2    8]\n",
            " [   0    0    0 1073    1   11   59]\n",
            " [   1    0   13    2  622    0   16]\n",
            " [   3    0    1   17    1  640   12]\n",
            " [   3    0    0   91    7    6  774]] \n",
            "\n",
            "Relatório de classificação Rede Neural MLP: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    Barbunya       0.94      0.90      0.92       436\n",
            "      Bombay       1.00      1.00      1.00       171\n",
            "        Cali       0.93      0.94      0.93       532\n",
            "    Dermason       0.91      0.94      0.92      1144\n",
            "       Horoz       0.97      0.95      0.96       654\n",
            "       Seker       0.97      0.95      0.96       674\n",
            "        Sira       0.88      0.88      0.88       881\n",
            "\n",
            "    accuracy                           0.93      4492\n",
            "   macro avg       0.94      0.94      0.94      4492\n",
            "weighted avg       0.93      0.93      0.93      4492\n",
            "\n",
            "Acurácia Rede Neural MLP: 92.92%.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luBuatyA6p_y"
      },
      "source": [
        "#Ensamble de Redes Neurais\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ef-y7fLh6p_y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "019ac3f5-8a73-4727-d085-4fa06f70b789"
      },
      "source": [
        "#Ensamble heterogêneo\n",
        "\n",
        "#Instanciando o modelo\n",
        "rfr = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
        "\n",
        "# Treinando o modelo no dataset de treino\n",
        "rfr.fit(X_train, y_train_vet)\n",
        "\n",
        "#Avaliando o desempenho através do erro médio absoluto\n",
        "#score = -1*cross_val_score(rfr, X_test, y_test_bin, cv = 10, scoring = 'neg_mean_absolute_error').mean()\n",
        "\n",
        "#print(score)\n",
        "#Aplicando o modelo\n",
        "y_pred_en = rfr.predict(X_test)\n",
        "\n",
        "#Calcula o erro absoluto\n",
        "errors = abs(y_pred_en - y_test_vet)\n",
        "\n",
        "#Calcula a porcentagem do erro absoluto medio(MAPE)\n",
        "mape = 100 * (errors / y_test_vet)\n",
        "\n",
        "# Imprimindo a matriz confusa\n",
        "#print(\"Matriz Confusa Ensamble heterogêneo: \")\n",
        "#print(confusion_matrix(y_test_bin, y_pred_en, \"\\n\"))  \n",
        "\n",
        "# Imprimindo o relatório de classificação\n",
        "#print(\"Relatório de classificação Ensamble heterogêneo: \\n\", classification_report(y_test_bin, y_pred_en, target_names=labels))\n",
        "\n",
        "#Imprimindo a acurácia do modelo\n",
        "#accuracy_en = accuracy_score(y_test_bin, y_pred_en) * 100\n",
        "#print(\"Acurácia Ensamble heterogêneo: {:.2f}%.\".format(accuracy_en))\n",
        "accuracy_en = 100 - np.mean(mape)\n",
        "print('Acurácia Ensamble heterogêneo:', round(accuracy_en, 2), '%.')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Acurácia Ensamble heterogêneo: nan %.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:20: RuntimeWarning: divide by zero encountered in true_divide\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:20: RuntimeWarning: invalid value encountered in true_divide\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}