{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1-final"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.9.1 64-bit",
      "metadata": {
        "interpreter": {
          "hash": "799275936fb7c37caa15961302e1f6bc5b6f09e92bdf39e5acfe019a9d46a476"
        }
      }
    },
    "colab": {
      "name": "dry_bean_tunning.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dvIz-1A6p_l"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy import dstack\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense\n",
        "from keras.optimizers import SGD\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.models import load_model\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import cross_val_score, cross_validate, ShuffleSplit\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns \n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_l1IvTAd6p_u"
      },
      "source": [
        "# Carregando o dataset\n",
        "df = pd.read_excel(\"https://raw.githubusercontent.com/irvin-s/smd_project/main/dataset/dry_bean_dataset.xls\")"
      ],
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWe9myuZ6p_v"
      },
      "source": [
        "# Atribuindo os labels para a classe reposta\n",
        "labels = [\"Barbunya\", \"Bombay\", \"Cali\", \"Dermason\", \"Horoz\", \"Seker\", \"Sira\"]\n",
        "\n",
        "# Dividindo a base em treino e teste\n",
        "X = df.drop(\"Class\", axis=1)\n",
        "y = df[\"Class\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, stratify=y,test_size=0.33, random_state=123)\n",
        "\n",
        "# Normalizando os dados\n",
        "ss = StandardScaler()\n",
        "X_train_norm = ss.fit_transform(X_train)\n",
        "X_test_norm = ss.fit_transform(X_test)\n",
        "\n",
        "# Transformando a variável cartegorica em binária\n",
        "labelencoder = LabelEncoder()\n",
        "y_train_bin = labelencoder.fit_transform(y_train)\n",
        "y_test_bin = labelencoder.fit_transform(y_test)"
      ],
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3LA8cqW6p_v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 758
        },
        "outputId": "26c6c2bd-fc42-4a93-e05a-559c127a8148"
      },
      "source": [
        "# Aplicando o modelo KNN\n",
        "\n",
        "# Definindo o valor de vizinhos\n",
        "classifier = KNeighborsClassifier(n_neighbors=15)\n",
        "\n",
        "# Treinar o modelo, com os dados de treinamento\n",
        "classifier.fit(X_train_norm, y_train_bin)\n",
        "\n",
        "# Prever os valores de y com dos dados de X_test\n",
        "y_pred = classifier.predict(X_test_norm)\n",
        "\n",
        "# Imprimindo a matriz confusa\n",
        "print(\"Matriz Confusa KNN: \")\n",
        "print(confusion_matrix(y_test_bin, y_pred), \"\\n\")  \n",
        "\n",
        "# Imprimindo o gráfico de caixa\n",
        "print(\"Boxplot KNN: \")\n",
        "sns.boxplot(x=y_test_bin,y=y_pred, data=df)\n",
        "plt.show()\n",
        "print(\"\\n\")  \n",
        "\n",
        "# Imprimindo o relatório de classificação\n",
        "print(\"Relatório de classificação KNN: \\n\", classification_report(y_test_bin, y_pred, target_names=labels))  \n",
        "\n",
        "# Imprimindo o quão acurado foi o modelo\n",
        "acu_knn = accuracy_score(y_test_bin, y_pred) * 100\n",
        "print(\"Acurácia KNN(Holdout): {:.2f}%\".format(acu_knn))\n",
        "\n",
        "# Validação cruzada com k-fold e k=10\n",
        "scores_knn = cross_val_score(classifier, X_test_norm, y_test_bin, cv=10, scoring='accuracy')\n",
        "print(\"Acurácia média KNN(k-fold): {:.2f}% e desvio padrão\".format(scores_knn.mean()*100), scores_knn.std())"
      ],
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Matriz Confusa KNN: \n",
            "[[ 389    0   29    0    1    4   14]\n",
            " [   0  172    0    0    0    0    0]\n",
            " [  14    0  507    0   10    1    6]\n",
            " [   0    0    0 1072    1   20   77]\n",
            " [   1    0    8    4  602    0   21]\n",
            " [   6    0    0    9    0  627   27]\n",
            " [   2    0    2   79   10    9  768]] \n",
            "\n",
            "Boxplot KNN: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Relatório de classificação KNN: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    Barbunya       0.94      0.89      0.92       437\n",
            "      Bombay       1.00      1.00      1.00       172\n",
            "        Cali       0.93      0.94      0.94       538\n",
            "    Dermason       0.92      0.92      0.92      1170\n",
            "       Horoz       0.96      0.95      0.96       636\n",
            "       Seker       0.95      0.94      0.94       669\n",
            "        Sira       0.84      0.88      0.86       870\n",
            "\n",
            "    accuracy                           0.92      4492\n",
            "   macro avg       0.94      0.93      0.93      4492\n",
            "weighted avg       0.92      0.92      0.92      4492\n",
            "\n",
            "Acurácia KNN(Holdout): 92.10%\n",
            "Acurácia média KNN(k-fold): 91.85% e desvio padrão 0.01096965867903345\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2bfgfEB6p_w"
      },
      "source": [
        "# Aplicando a Árvore de decisão\n",
        "\n",
        "# Instanciando o modelo\n",
        "modeldt = DecisionTreeClassifier()\n",
        "\n",
        "# Treinar o modelo\n",
        "modeldt.fit(X_train, y_train_bin)\n",
        "\n",
        "# Aplicar o modelo ao treinamento e ao teste\n",
        "predicted_test_y = modeldt.predict(X_test)\n",
        "\n",
        "predicted_train_y = modeldt.predict(X_train)"
      ],
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwV9XKgP6p_x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "766ecdf6-84ae-4c1c-d12f-09171811a7b9"
      },
      "source": [
        "# Imprimindo a matriz confusa\n",
        "print(\"Matriz Confusa Decision Tree: \")\n",
        "print(confusion_matrix(y_test_bin, predicted_test_y), \"\\n\")  \n",
        "\n",
        "# Imprimindo o relatório de classificação\n",
        "print(\"Relatório de classificação Decision Tree: \\n\", classification_report(y_test_bin, predicted_test_y, target_names=labels)) \n",
        "\n",
        "# Imprimindo a acurácia do modelo\n",
        "accuracy_dt = accuracy_score(y_test_bin, predicted_test_y) * 100\n",
        "print(\"Acurácia Decision Tree(Holdout): {:.2f}%.\".format(accuracy_dt))\n",
        "\n",
        "# Validação cruzada com k-fold e k=10\n",
        "scores_dt = cross_val_score(modeldt, X_test, y_test_bin, cv=10, scoring='accuracy')\n",
        "print(\"Acurácia média Decision Tree(k-fold): {:.2f}% e desvio padrão\".format(scores_dt.mean()*100), scores_dt.std())"
      ],
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Matriz Confusa Decision Tree: \n",
            "[[ 395    0   24    1    2    4   11]\n",
            " [   1  170    1    0    0    0    0]\n",
            " [  26    0  485    0   21    1    5]\n",
            " [   0    0    0 1029    1   26  114]\n",
            " [   5    0   10    4  597    0   20]\n",
            " [   9    0    0   20    0  619   21]\n",
            " [  19    0    5   97   16   22  711]] \n",
            "\n",
            "Relatório de classificação Decision Tree: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    Barbunya       0.87      0.90      0.89       437\n",
            "      Bombay       1.00      0.99      0.99       172\n",
            "        Cali       0.92      0.90      0.91       538\n",
            "    Dermason       0.89      0.88      0.89      1170\n",
            "       Horoz       0.94      0.94      0.94       636\n",
            "       Seker       0.92      0.93      0.92       669\n",
            "        Sira       0.81      0.82      0.81       870\n",
            "\n",
            "    accuracy                           0.89      4492\n",
            "   macro avg       0.91      0.91      0.91      4492\n",
            "weighted avg       0.89      0.89      0.89      4492\n",
            "\n",
            "Acurácia Decision Tree(Holdout): 89.18%.\n",
            "Acurácia média Decision Tree(k-fold): 88.47% e desvio padrão 0.010653517195710439\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWM5MLyt6p_x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b77792f-3070-4148-81ab-278447b92a76"
      },
      "source": [
        "# Aplicando a Random Forest\n",
        "\n",
        "# Instanciando o modelo\n",
        "rf = RandomForestClassifier(90, max_depth=10, random_state=42)\n",
        "rf.fit(X_train,y_train_bin)\n",
        "\n",
        "# Aplicando o modelo\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "\n",
        "# Imprimindo a matriz confusa\n",
        "print(\"Matriz Confusa Random Forest: \")\n",
        "print(confusion_matrix(y_test_bin, y_pred_rf), \"\\n\")  \n",
        "\n",
        "# Imprimindo o relatório de classificação\n",
        "print(\"Relatório de classificação Random Forest: \\n\", classification_report(y_test_bin, y_pred_rf, target_names=labels)) \n",
        "\n",
        "# Imprimindo a acurácia do modelo\n",
        "accuracy_rf = accuracy_score(y_test_bin, y_pred_rf) * 100\n",
        "print(\"Acurácia Random Forest(Holdout): {:.2f}%.\".format(accuracy_rf))\n",
        "\n",
        "# Validação cruzada com k-fold e k=10\n",
        "scores_rf = cross_val_score(rf, X_test, y_test_bin, cv=10, scoring='accuracy')\n",
        "print(\"Acurácia médiaRandom Forest(k-fold): {:.2f}% e desvio padrão\".format(scores_rf.mean()*100), scores_rf.std())"
      ],
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Matriz Confusa Random Forest: \n",
            "[[ 389    0   29    0    0    4   15]\n",
            " [   2  170    0    0    0    0    0]\n",
            " [  20    0  496    0   14    1    7]\n",
            " [   0    0    0 1082    1   18   69]\n",
            " [   1    0    8    6  598    0   23]\n",
            " [   3    0    0   14    0  630   22]\n",
            " [   3    0    2   89    7   16  753]] \n",
            "\n",
            "Relatório de classificação Random Forest: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    Barbunya       0.93      0.89      0.91       437\n",
            "      Bombay       1.00      0.99      0.99       172\n",
            "        Cali       0.93      0.92      0.92       538\n",
            "    Dermason       0.91      0.92      0.92      1170\n",
            "       Horoz       0.96      0.94      0.95       636\n",
            "       Seker       0.94      0.94      0.94       669\n",
            "        Sira       0.85      0.87      0.86       870\n",
            "\n",
            "    accuracy                           0.92      4492\n",
            "   macro avg       0.93      0.92      0.93      4492\n",
            "weighted avg       0.92      0.92      0.92      4492\n",
            "\n",
            "Acurácia Random Forest(Holdout): 91.67%.\n",
            "Acurácia médiaRandom Forest(k-fold): 91.27% e desvio padrão 0.01098784093815674\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwxVsj3h6p_y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77633ab2-f82b-47a3-b1d5-3f3aa5ab0f21"
      },
      "source": [
        "# Aplicando a Rede Neural MLP\n",
        "\n",
        "# Vetorizar a classe resposta\n",
        "lb = LabelBinarizer()\n",
        "y_train_vet = lb.fit_transform(y_train)\n",
        "y_test_vet = lb.fit_transform(y_test)\n",
        "\n",
        "# Instanciado o modelo\n",
        "modelNN = Sequential()\n",
        "modelNN.add(Dense(50, input_dim=16, activation='relu'))\n",
        "modelNN.add(Dense(7, activation='softmax'))\n",
        "modelNN.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Realizando o treinamento\n",
        "modelNN.fit(X_train_norm, y_train_vet, batch_size=128, epochs=300, verbose=0, validation_data=(X_test_norm, y_test_vet))\n",
        "\n",
        "def model_NN_K():\n",
        "  # Instanciado o modelo\n",
        "  modelNN_K = Sequential()\n",
        "  modelNN_K.add(Dense(50, input_dim=16, activation='relu'))\n",
        "  modelNN_K.add(Dense(7, activation='softmax'))\n",
        "  modelNN_K.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  return modelNN_K\n",
        "\n",
        "# Cria o modelo K\n",
        "modelNN_K = KerasClassifier(build_fn=model_NN_K, nb_epoch=300, batch_size=128, verbose=0)\n",
        "\n",
        "# Realizando o treinamento K\n",
        "modelNN_K.fit(X_train_norm, y_train_vet, validation_data=(X_test_norm, y_test_vet))\n",
        "\n",
        "# Avalidando a Rede Neural \n",
        "predictions = modelNN.predict(X_test_norm, batch_size=128)\n",
        "\n",
        "# Imprimindo a matriz confusa\n",
        "print(\"Matriz Confusa Rede Neural MLP: \")\n",
        "print(confusion_matrix(y_test_vet.argmax(axis=1), predictions.argmax(axis=1)), \"\\n\")  \n",
        "\n",
        "# Imprimindo o relatório de classificação\n",
        "print(\"Relatório de classificação Rede Neural MLP: \\n\", classification_report(y_test_vet.argmax(axis=1), predictions.argmax(axis=1), target_names=labels, zero_division=0))\n",
        "\n",
        "# Imprimindo a acurácia do modelo\n",
        "accuracy_nn = accuracy_score(y_test_vet.argmax(axis=1), predictions.argmax(axis=1)) * 100\n",
        "print(\"Acurácia Rede Neural MLP(Holdout): {:.2f}%.\".format(accuracy_nn))\n",
        "\n",
        "# Validação cruzada com k-fold e k=10\n",
        "scores_nn = cross_val_score(modelNN_K, X_test_norm, y_test_vet.argmax(axis=1), cv=10, scoring='accuracy')\n",
        "print(\"Acurácia média Rede Neural MLP(k-fold): {:.2f}% e desvio padrão\".format(scores_nn.mean()*100), scores_nn.std())"
      ],
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Matriz Confusa Rede Neural MLP: \n",
            "[[ 399    0   21    0    2    3   12]\n",
            " [   0  172    0    0    0    0    0]\n",
            " [  16    0  505    0   10    1    6]\n",
            " [   0    0    0 1062    2   16   90]\n",
            " [   2    0    8    7  599    0   20]\n",
            " [   5    0    1   10    0  634   19]\n",
            " [   1    0    1   62   12    6  788]] \n",
            "\n",
            "Relatório de classificação Rede Neural MLP: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    Barbunya       0.94      0.91      0.93       437\n",
            "      Bombay       1.00      1.00      1.00       172\n",
            "        Cali       0.94      0.94      0.94       538\n",
            "    Dermason       0.93      0.91      0.92      1170\n",
            "       Horoz       0.96      0.94      0.95       636\n",
            "       Seker       0.96      0.95      0.95       669\n",
            "        Sira       0.84      0.91      0.87       870\n",
            "\n",
            "    accuracy                           0.93      4492\n",
            "   macro avg       0.94      0.94      0.94      4492\n",
            "weighted avg       0.93      0.93      0.93      4492\n",
            "\n",
            "Acurácia Rede Neural MLP(Holdout): 92.59%.\n",
            "Acurácia média Rede Neural MLP(k-fold): 62.42% e desvio padrão 0.04257382388478727\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luBuatyA6p_y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14ef7fa7-6b60-44a1-9e6a-55d5a96b3acf"
      },
      "source": [
        "# Ensamble de Redes Neurais\n",
        "\n",
        "# Função com o modelo\n",
        "def gera_modelo(X_tr, y_tr):\n",
        "  # Instanciado o modelo\n",
        "  model = Sequential()\n",
        "  model.add(Dense(50, input_dim=16, activation='relu'))\n",
        "  model.add(Dense(7, activation='softmax'))\n",
        "  \n",
        "  # Compilando o modelo\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "  # Treinando o modelo\n",
        "  model.fit(X_tr, y_tr, epochs=300, batch_size=128, verbose=0)\n",
        "\n",
        "  return model\n",
        "\n",
        "# Diretório para armazenar cada modelo gerado\n",
        "makedirs('modelos')\n",
        "\n",
        "# Treina e salva os modelos\n",
        "n_members = 5\n",
        "for i in range(n_members):\n",
        "\t#Treina o modelo\n",
        "\tmodel = gera_modelo(X_train_norm, y_train_vet)\n",
        "\t#Salva o modelo\n",
        "\tfilename = 'modelos/modelo_' + str(i + 1) + '.h5'\n",
        "\tmodel.save(filename)\n",
        "\tprint('>Salvo %s' % filename)"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">Salvo modelos/modelo_1.h5\n",
            ">Salvo modelos/modelo_2.h5\n",
            ">Salvo modelos/modelo_3.h5\n",
            ">Salvo modelos/modelo_4.h5\n",
            ">Salvo modelos/modelo_5.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mFEMXMMXCTuR",
        "outputId": "89877d32-7ba3-4c1d-8fbe-afab829e164b"
      },
      "source": [
        "# Carregar os modelos salvos\n",
        "def carregar_modelos(n_models):\n",
        "\tall_models = list()\n",
        "\tfor i in range(n_models):\n",
        "\t\t# Define o nome do modelo\n",
        "\t\tfilename = 'modelos/modelo_' + str(i + 1) + '.h5'\n",
        "\t\t# Carrega o arquivo com o modelo\n",
        "\t\tmodel = load_model(filename)\n",
        "\t\t# Adicionar o modelo a uma lista\n",
        "\t\tall_models.append(model)\n",
        "\t\tprint('>Carregando %s' % filename)\n",
        "\treturn all_models\n",
        "\n",
        "# Carregar todos os modelos\n",
        "n_members = 5\n",
        "members = carregar_modelos(n_members)\n",
        "print('Total de modelos carregados: %d' % len(members))"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">Carregando modelos/modelo_1.h5\n",
            ">Carregando modelos/modelo_2.h5\n",
            ">Carregando modelos/modelo_3.h5\n",
            ">Carregando modelos/modelo_4.h5\n",
            ">Carregando modelos/modelo_5.h5\n",
            "Total de modelos carregados: 5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nm4qpwfqDcCg",
        "outputId": "b89936e7-d622-4798-be20-8628ee17847d"
      },
      "source": [
        "# Avaliando o desempenho individual\n",
        "i = 1\n",
        "for model in members:\n",
        "    _, acc = model.evaluate(X_test_norm, y_test_vet, verbose=0)\n",
        "    print('Acurácia modelo ' + str(i) + ': %.3f' % acc)\n",
        "    i = i + 1"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Acurácia modelo 1: 0.926\n",
            "Acurácia modelo 2: 0.929\n",
            "Acurácia modelo 3: 0.929\n",
            "Acurácia modelo 4: 0.925\n",
            "Acurácia modelo 5: 0.928\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2avjN-RjMvU"
      },
      "source": [
        "# Cria o modelo a partir dos modelos salvos e retorna um Ensemble\n",
        "def stacked_dataset(members, inputX):\n",
        "\tstackX = None\n",
        "\tfor model in members:\n",
        "\t\t# Avalia o modelo\n",
        "\t\tyhat = model.predict(inputX, verbose=0)\n",
        "\t\t# Armazena as predições [rows, members, probabilities]\n",
        "\t\tif stackX is None:\n",
        "\t\t\tstackX = yhat\n",
        "\t\telse:\n",
        "\t\t\tstackX = dstack((stackX, yhat))\n",
        "\t# Aglutina as prdições [rows, members x probabilities]\n",
        "\tstackX = stackX.reshape((stackX.shape[0], stackX.shape[1]*stackX.shape[2]))\n",
        "\treturn stackX\n",
        "\n",
        "# Treina um modelo com base nas saídas dos membros do ensamble\n",
        "def fit_stacked_model(members, inputX, inputy):\n",
        "\t# Cria um dataset usando o ensemble\n",
        "\tstackedX = stacked_dataset(members, inputX)\n",
        "\t# Treina o modelo\n",
        "\tmodel = LogisticRegression()\n",
        "\tmodel.fit(stackedX, inputy)\n",
        "\treturn model"
      ],
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-M0hySXlNrK"
      },
      "source": [
        "# Treina o modelo stacked utilizando o Ensemble\n",
        "model = fit_stacked_model(members, X_test_norm, y_test_bin)"
      ],
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBmjPIAZmQSO"
      },
      "source": [
        "# Classifica utilizando modelo Stacked\n",
        "def stacked_prediction(members, model, inputX):\n",
        "\t# Cria um conjunto de dados usando o Ensemble\n",
        "\tstackedX = stacked_dataset(members, inputX)\n",
        "\t# Faz a predição\n",
        "\tyhat = model.predict(stackedX)\n",
        "\treturn yhat"
      ],
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIvZqsUwnPfi",
        "outputId": "aa041c41-819e-477b-9dbb-a15f84bd6698"
      },
      "source": [
        "# Avaliando a predição realizada pelo Ensemble\n",
        "yhat = stacked_prediction(members, model, X_test_norm)\n",
        "acc = accuracy_score(y_test_bin, yhat)\n",
        "acc = acc*100\n",
        "\n",
        "# Imprimindo o relatório de classificação\n",
        "print(\"Relatório de classificação Ensamble de Redes Neurais: \\n\", classification_report(y_test_bin, yhat, target_names=labels, zero_division=0))\n",
        "\n",
        "# Acurácia do modelo\n",
        "print('Acurácia do Ensamble de Redes Neurais: {:.2f}%'.format(acc))\n",
        "\n",
        "# Validação cruzada com k-fold e k=10\n",
        "scores_en = cross_val_score(model, X_test_norm, y_test_bin, cv=10, scoring='accuracy')\n",
        "print(\"Acurácia média Ensamble de Redes Neurais(k-fold): {:.2f}% e desvio padrão\".format(scores_en.mean()*100), scores_en.std())"
      ],
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Relatório de classificação Ensamble de Redes Neurais: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    Barbunya       0.93      0.92      0.93       437\n",
            "      Bombay       1.00      1.00      1.00       172\n",
            "        Cali       0.95      0.93      0.94       538\n",
            "    Dermason       0.92      0.93      0.92      1170\n",
            "       Horoz       0.96      0.96      0.96       636\n",
            "       Seker       0.96      0.95      0.95       669\n",
            "        Sira       0.88      0.89      0.88       870\n",
            "\n",
            "    accuracy                           0.93      4492\n",
            "   macro avg       0.94      0.94      0.94      4492\n",
            "weighted avg       0.93      0.93      0.93      4492\n",
            "\n",
            "Acurácia do Ensamble de Redes Neurais: 93.05%\n",
            "Acurácia média Ensamble de Redes Neurais(k-fold): 92.30% e desvio padrão 0.005720070172797905\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ef-y7fLh6p_y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44c0ae5d-5113-4168-9ebe-6a7c2e5be274"
      },
      "source": [
        "#Ensamble heterogêneo\n",
        "\n",
        "#Instanciando o modelo\n",
        "rfr = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
        "\n",
        "# Treinando o modelo no dataset de treino\n",
        "rfr.fit(X_train, y_train_vet)\n",
        "\n",
        "#Aplicando o modelo\n",
        "y_pred_en = rfr.predict(X_test)\n",
        "\n",
        "#Avaliando o desempenho através do erro médio absoluto\n",
        "score_en = -1*cross_val_score(rfr, X_test, y_test_vet, cv = 10, scoring = 'neg_mean_absolute_error').mean()*100\n",
        "print(score_en)\n",
        "#Calcula o erro absoluto\n",
        "#errors = abs(y_pred_en - y_test_vet)\n",
        "\n",
        "#Calcula a porcentagem do erro absoluto medio(MAPE)\n",
        "#mape = 100 * (errors / y_test_vet)\n",
        "\n",
        "# Imprimindo a matriz confusa\n",
        "#print(\"Matriz Confusa Ensamble heterogêneo: \")\n",
        "#print(confusion_matrix(y_test_bin, y_pred_en, \"\\n\"))  \n",
        "\n",
        "# Imprimindo o relatório de classificação\n",
        "#print(\"Relatório de classificação Ensamble heterogêneo: \\n\", classification_report(y_test_bin, y_pred_en, target_names=labels))\n",
        "\n",
        "#Imprimindo a acurácia do modelo\n",
        "#accuracy_en = accuracy_score(y_test_bin, y_pred_en) * 100\n",
        "#print(\"Acurácia Ensamble heterogêneo: {:.2f}%.\".format(accuracy_en))\n",
        "#accuracy_en = 100 - np.mean(mape)\n",
        "#print('Acurácia Ensamble heterogêneo:', round(accuracy_en, 2), '%.')"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3.4635451338070498\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}