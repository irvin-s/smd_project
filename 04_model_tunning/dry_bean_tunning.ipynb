{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1-final"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.9.1 64-bit",
      "metadata": {
        "interpreter": {
          "hash": "799275936fb7c37caa15961302e1f6bc5b6f09e92bdf39e5acfe019a9d46a476"
        }
      }
    },
    "colab": {
      "name": "dry_bean_tunning.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dvIz-1A6p_l"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense\n",
        "from keras.optimizers import SGD\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_l1IvTAd6p_u"
      },
      "source": [
        "#Carregando o dataset\n",
        "df = pd.read_excel(\"https://raw.githubusercontent.com/irvin-s/smd_project/main/dataset/dry_bean_dataset.xls\")"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWe9myuZ6p_v"
      },
      "source": [
        "#atribuindo os labes para a classe reposta\n",
        "labels = [\"Barbunya\", \"Bombay\", \"Cali\", \"Dermason\", \"Horoz\", \"Seker\", \"Sira\"]\n",
        "\n",
        "#Dividindo a base em treino e teste\n",
        "X = df.drop(\"Class\", axis=1)\n",
        "y = df[\"Class\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.33, random_state=123)\n",
        "\n",
        "#Normalizando os dados\n",
        "ss = StandardScaler()\n",
        "X_train_norm = ss.fit_transform(X_train)\n",
        "X_test_norm = ss.fit_transform(X_test)\n",
        "\n",
        "#Transformando a variável cartegorica em binária\n",
        "labelencoder = LabelEncoder()\n",
        "y_train_bin = labelencoder.fit_transform(y_train)\n",
        "y_test_bin = labelencoder.fit_transform(y_test)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3LA8cqW6p_v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8db9f981-143b-4853-e82b-45032bb64498"
      },
      "source": [
        "#Aplicando o modelo KNN\n",
        "\n",
        "#Definindo o valor de vizinhos\n",
        "classifier = KNeighborsClassifier(n_neighbors=15)\n",
        "\n",
        "#Treinar o modelo, com os dados de treinamento\n",
        "classifier.fit(X_train_norm, y_train_bin)\n",
        "\n",
        "#Prever os valores de y com dos dados de X_test\n",
        "y_pred = classifier.predict(X_test_norm)\n",
        "\n",
        "# Imprimindo a matriz confusa\n",
        "print(\"Matriz Confusa KNN: \")\n",
        "print(confusion_matrix(y_test_bin, y_pred), \"\\n\")  \n",
        "\n",
        "# Imprimindo o relatório de classificação\n",
        "print(\"Relatório de classificação KNN: \\n\", classification_report(y_test_bin, y_pred, target_names=labels))  \n",
        "\n",
        "# Imprimindo o quão acurado foi o modelo\n",
        "acu_knn = accuracy_score(y_test_bin, y_pred) * 100\n",
        "print(\"Acurácia KNN: {:.2f}%\".format(acu_knn))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Matriz Confusa: \n",
            "[[ 384    0   34    0    2    3   13]\n",
            " [   0  171    0    0    0    0    0]\n",
            " [  11    0  507    0    5    2    7]\n",
            " [   0    0    0 1064    0   12   68]\n",
            " [   0    0   14    2  620    0   18]\n",
            " [   2    0    0   19    1  628   24]\n",
            " [   1    0    0   93    9    6  772]] \n",
            "\n",
            "Relatório de classificação: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    Barbunya       0.96      0.88      0.92       436\n",
            "      Bombay       1.00      1.00      1.00       171\n",
            "        Cali       0.91      0.95      0.93       532\n",
            "    Dermason       0.90      0.93      0.92      1144\n",
            "       Horoz       0.97      0.95      0.96       654\n",
            "       Seker       0.96      0.93      0.95       674\n",
            "        Sira       0.86      0.88      0.87       881\n",
            "\n",
            "    accuracy                           0.92      4492\n",
            "   macro avg       0.94      0.93      0.93      4492\n",
            "weighted avg       0.92      0.92      0.92      4492\n",
            "\n",
            "Acurácia KNN: 92.30%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2bfgfEB6p_w"
      },
      "source": [
        "#Aplicando a Árvore de decisão\n",
        "\n",
        "#Instanciando o modelo\n",
        "model = DecisionTreeClassifier()\n",
        "\n",
        "# Treinar o modelo\n",
        "model.fit(X_train, y_train_bin)\n",
        "\n",
        "# Aplicar o modelo ao treinamento e ao teste\n",
        "predicted_test_y = model.predict(X_test)\n",
        "\n",
        "predicted_train_y = model.predict(X_train)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwV9XKgP6p_x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee6d682f-d4c9-4140-e69f-7779f8cd472b"
      },
      "source": [
        "# Imprimindo a matriz confusa\n",
        "print(\"Matriz Confusa Decision Tree: \")\n",
        "print(confusion_matrix(y_test_bin, predicted_test_y), \"\\n\")  \n",
        "\n",
        "# Imprimindo o relatório de classificação\n",
        "print(\"Relatório de classificação Decision Tree: \\n\", classification_report(y_test_bin, predicted_test_y, target_names=labels)) \n",
        "\n",
        "#Imprimindo a acurácia do modelo\n",
        "accuracy_dt = accuracy_score(y_test_bin, predicted_test_y) * 100\n",
        "print (\"Acurácia Decision Tree: {:.2f}%.\".format(accuracy_dt))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Matriz Confusa Decision Tree: \n",
            "[[ 377    0   35    0    7    5   12]\n",
            " [   1  170    0    0    0    0    0]\n",
            " [  26    0  488    0   11    2    5]\n",
            " [   0    0    0 1039    5   16   84]\n",
            " [   2    0   12    5  614    0   21]\n",
            " [   8    0    0   29    0  613   24]\n",
            " [   7    0    1   91   26   15  741]] \n",
            "\n",
            "Relatório de classificação Decision Tree: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    Barbunya       0.90      0.86      0.88       436\n",
            "      Bombay       1.00      0.99      1.00       171\n",
            "        Cali       0.91      0.92      0.91       532\n",
            "    Dermason       0.89      0.91      0.90      1144\n",
            "       Horoz       0.93      0.94      0.93       654\n",
            "       Seker       0.94      0.91      0.93       674\n",
            "        Sira       0.84      0.84      0.84       881\n",
            "\n",
            "    accuracy                           0.90      4492\n",
            "   macro avg       0.91      0.91      0.91      4492\n",
            "weighted avg       0.90      0.90      0.90      4492\n",
            "\n",
            "Acurácia Decision Tree: 89.98%.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWM5MLyt6p_x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81588edd-c41b-4ec4-c013-d1fb7756f5af"
      },
      "source": [
        "#Aplicando a Random Forest\n",
        "\n",
        "#Instanciando o modelo\n",
        "rf = RandomForestClassifier(80, max_depth=10, random_state=42)\n",
        "rf.fit(X_train,y_train_bin)\n",
        "\n",
        "#Resultado do modelo\n",
        "score_rf = cross_val_score(rf, X, y, cv=5, scoring='accuracy').mean()\n",
        "score_rf = score_rf * 100\n",
        "print(\"Acurácia Random Forest: {:.2f}%.\".format(score_rf))"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Acurácia Random Forest: 61.78%.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwxVsj3h6p_y",
        "outputId": "775dbbaa-37b3-44a1-89f6-813e13e35336",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 972
        }
      },
      "source": [
        "#Aplicando a Rede Neural MLP\n",
        "\n",
        "#Instanciado o modelo\n",
        "modelNN = Sequential()\n",
        "modelNN.add(Dense(128, input_shape=(16,), activation=\"sigmoid\"))\n",
        "modelNN.add(Dense(64, activation=\"sigmoid\"))\n",
        "modelNN.add(Dense(7, activation=\"softmax\"))\n",
        "\n",
        "#Vetorizar a classe resposta\n",
        "lb = LabelBinarizer()\n",
        "y_train_vet = lb.fit_transform(y_train)\n",
        "y_test_vet = lb.fit_transform(y_test)\n",
        "\n",
        "#Realizando o treinamento\n",
        "modelNN.compile(optimizer=SGD(0.01), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "H = modelNN.fit(X_train_norm, y_train_vet, batch_size=128, epochs=10, verbose=2, validation_data=(X_test_norm, y_test_vet))\n",
        "\n",
        "#Avalidando a Rede Neural \n",
        "predictions = modelNN.predict(X_test_norm, batch_size=128)\n",
        "print(classification_report(y_test_vet.argmax(axis=1), predictions.argmax(axis=1), target_names=labels))\n",
        "\n",
        "#Matriz confusa\n",
        "cnf_matrix = confusion_matrix(X_test_norm, predictions.argmax(axis=1))"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "72/72 - 1s - loss: 1.8717 - accuracy: 0.2402 - val_loss: 1.8030 - val_accuracy: 0.2547\n",
            "Epoch 2/10\n",
            "72/72 - 0s - loss: 1.7805 - accuracy: 0.2634 - val_loss: 1.7698 - val_accuracy: 0.2547\n",
            "Epoch 3/10\n",
            "72/72 - 0s - loss: 1.7532 - accuracy: 0.2634 - val_loss: 1.7445 - val_accuracy: 0.2547\n",
            "Epoch 4/10\n",
            "72/72 - 0s - loss: 1.7281 - accuracy: 0.2634 - val_loss: 1.7197 - val_accuracy: 0.2547\n",
            "Epoch 5/10\n",
            "72/72 - 0s - loss: 1.7023 - accuracy: 0.2635 - val_loss: 1.6932 - val_accuracy: 0.2549\n",
            "Epoch 6/10\n",
            "72/72 - 0s - loss: 1.6749 - accuracy: 0.2643 - val_loss: 1.6648 - val_accuracy: 0.2558\n",
            "Epoch 7/10\n",
            "72/72 - 0s - loss: 1.6458 - accuracy: 0.2706 - val_loss: 1.6347 - val_accuracy: 0.2812\n",
            "Epoch 8/10\n",
            "72/72 - 0s - loss: 1.6149 - accuracy: 0.3091 - val_loss: 1.6039 - val_accuracy: 0.2861\n",
            "Epoch 9/10\n",
            "72/72 - 0s - loss: 1.5827 - accuracy: 0.3253 - val_loss: 1.5706 - val_accuracy: 0.3533\n",
            "Epoch 10/10\n",
            "72/72 - 0s - loss: 1.5489 - accuracy: 0.3745 - val_loss: 1.5363 - val_accuracy: 0.3713\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Barbunya       0.00      0.00      0.00       436\n",
            "      Bombay       0.00      0.00      0.00       171\n",
            "        Cali       0.09      0.03      0.05       532\n",
            "    Dermason       0.39      1.00      0.56      1144\n",
            "       Horoz       0.59      0.77      0.67       654\n",
            "       Seker       0.00      0.00      0.00       674\n",
            "        Sira       0.01      0.01      0.01       881\n",
            "\n",
            "    accuracy                           0.37      4492\n",
            "   macro avg       0.15      0.26      0.18      4492\n",
            "weighted avg       0.20      0.37      0.25      4492\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-29df1dc9ddaf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m#Matriz confusa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mcnf_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \"\"\"\n\u001b[0;32m--> 268\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is not supported\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0;32m---> 90\u001b[0;31m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of continuous-multioutput and multiclass targets"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luBuatyA6p_y"
      },
      "source": [
        "#Ensamble de Redes Neurais\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ef-y7fLh6p_y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "163a45f7-2ed0-4a6d-c372-c942df894acd"
      },
      "source": [
        "#Ensamble heterogêneo\n",
        "\n",
        "#Instanciando o modelo\n",
        "rfr = RandomForestRegressor(n_estimators = 200, random_state = 42)\n",
        "\n",
        "# Treinando o modelo no dataset de treino\n",
        "rfr.fit(X_train, y_train_bin)\n",
        "\n",
        "#Avaliando o desempenho através do erro médio absoluto\n",
        "score = -1*cross_val_score(rfr, X_test, y_test_bin, cv = 10, scoring = 'neg_mean_absolute_error').mean()\n",
        "\n",
        "print(score)\n",
        "\n",
        "#Aplicando o modelo\n",
        "rfr.predict(X_test)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.2891363424894827\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3.   , 5.995, 1.   , ..., 6.   , 3.905, 4.74 ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    }
  ]
}