{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1-final"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.9.1 64-bit",
      "metadata": {
        "interpreter": {
          "hash": "799275936fb7c37caa15961302e1f6bc5b6f09e92bdf39e5acfe019a9d46a476"
        }
      }
    },
    "colab": {
      "name": "dry_bean_tunning.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXf1cMk4GyYh",
        "outputId": "508c488e-7360-4903-b389-223dbb305e47"
      },
      "source": [
        "!pip install deslib"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting deslib\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c3/be/e9c723932b580de822e78418855d77bfb8ef4bbc0a2ff6ee801b50055712/DESlib-0.3.5-py3-none-any.whl (158kB)\n",
            "\r\u001b[K     |██                              | 10kB 13.8MB/s eta 0:00:01\r\u001b[K     |████▏                           | 20kB 19.3MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 30kB 21.9MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 40kB 24.5MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 51kB 25.4MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 61kB 24.7MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 71kB 22.0MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 81kB 19.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 92kB 19.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 102kB 20.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 112kB 20.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 122kB 20.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 133kB 20.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 143kB 20.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 153kB 20.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 163kB 20.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from deslib) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from deslib) (0.22.2.post1)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.7/dist-packages (from deslib) (1.19.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.0->deslib) (1.0.1)\n",
            "Installing collected packages: deslib\n",
            "Successfully installed deslib-0.3.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dvIz-1A6p_l"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy import dstack\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense\n",
        "from keras.optimizers import SGD\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.models import load_model\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import cross_val_score, cross_validate, ShuffleSplit\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from deslib.static import StackedClassifier\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from os import makedirs\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_l1IvTAd6p_u"
      },
      "source": [
        "# Carregando o dataset\n",
        "df = pd.read_excel(\"https://raw.githubusercontent.com/irvin-s/smd_project/main/00_dataset/dry_bean_dataset.xls\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWe9myuZ6p_v"
      },
      "source": [
        "# Atribuindo os labels para a classe reposta\n",
        "labels = [\"Barbunya\", \"Bombay\", \"Cali\", \"Dermason\", \"Horoz\", \"Seker\", \"Sira\"]\n",
        "\n",
        "# Dividindo a base em treino e teste\n",
        "X = df.drop(\"Class\", axis=1)\n",
        "y = df[\"Class\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, stratify=y,test_size=0.33, random_state=123)\n",
        "\n",
        "# Normalizando os dados\n",
        "ss = StandardScaler()\n",
        "X_train_norm = ss.fit_transform(X_train)\n",
        "X_test_norm = ss.fit_transform(X_test)\n",
        "\n",
        "# Transformando a variável cartegorica em binária\n",
        "labelencoder = LabelEncoder()\n",
        "y_train_bin = labelencoder.fit_transform(y_train)\n",
        "y_test_bin = labelencoder.fit_transform(y_test)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3LA8cqW6p_v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3349797c-2db9-443b-e143-af71a7d13b66"
      },
      "source": [
        "# Aplicando o modelo KNN\n",
        "\n",
        "# Definindo o valor de vizinhos\n",
        "classifier = KNeighborsClassifier(n_neighbors=15)\n",
        "\n",
        "# Treinar o modelo, com os dados de treinamento\n",
        "classifier.fit(X_train_norm, y_train_bin)\n",
        "\n",
        "# Prever os valores de y com dos dados de X_test\n",
        "y_pred = classifier.predict(X_test_norm)\n",
        "\n",
        "# Imprimindo a matriz confusa\n",
        "print(\"Matriz Confusa KNN: \")\n",
        "print(confusion_matrix(y_test_bin, y_pred), \"\\n\")  \n",
        "\n",
        "# Imprimindo o relatório de classificação\n",
        "print(\"Relatório de classificação KNN: \\n\", classification_report(y_test_bin, y_pred, target_names=labels))  \n",
        "\n",
        "# Imprimindo o quão acurado foi o modelo\n",
        "acu_knn = accuracy_score(y_test_bin, y_pred) * 100\n",
        "print(\"Acurácia KNN(Holdout): {:.2f}%\".format(acu_knn))\n",
        "\n",
        "# Validação cruzada com k-fold e k=10\n",
        "scores_knn = cross_val_score(classifier, X_test_norm, y_test_bin, cv=10, scoring='accuracy')\n",
        "print(\"Acurácia média KNN(k-fold): {:.2f}% e desvio padrão\".format(scores_knn.mean()*100), scores_knn.std())"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Matriz Confusa KNN: \n",
            "[[ 389    0   29    0    1    4   14]\n",
            " [   0  172    0    0    0    0    0]\n",
            " [  14    0  507    0   10    1    6]\n",
            " [   0    0    0 1072    1   20   77]\n",
            " [   1    0    8    4  602    0   21]\n",
            " [   6    0    0    9    0  627   27]\n",
            " [   2    0    2   79   10    9  768]] \n",
            "\n",
            "Relatório de classificação KNN: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    Barbunya       0.94      0.89      0.92       437\n",
            "      Bombay       1.00      1.00      1.00       172\n",
            "        Cali       0.93      0.94      0.94       538\n",
            "    Dermason       0.92      0.92      0.92      1170\n",
            "       Horoz       0.96      0.95      0.96       636\n",
            "       Seker       0.95      0.94      0.94       669\n",
            "        Sira       0.84      0.88      0.86       870\n",
            "\n",
            "    accuracy                           0.92      4492\n",
            "   macro avg       0.94      0.93      0.93      4492\n",
            "weighted avg       0.92      0.92      0.92      4492\n",
            "\n",
            "Acurácia KNN(Holdout): 92.10%\n",
            "Acurácia média KNN(k-fold): 91.85% e desvio padrão 0.01096965867903345\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2bfgfEB6p_w"
      },
      "source": [
        "# Aplicando a Árvore de decisão\n",
        "\n",
        "# Instanciando o modelo\n",
        "modeldt = DecisionTreeClassifier(max_depth=13)\n",
        "\n",
        "# Treinar o modelo\n",
        "modeldt.fit(X_train, y_train_bin)\n",
        "\n",
        "# Aplicar o modelo ao treinamento e ao teste\n",
        "predicted_test_y = modeldt.predict(X_test)\n",
        "\n",
        "predicted_train_y = modeldt.predict(X_train)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwV9XKgP6p_x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2932f19-8224-4315-9ad2-1099e2860da1"
      },
      "source": [
        "# Imprimindo a matriz confusa\n",
        "print(\"Matriz Confusa Decision Tree: \")\n",
        "print(confusion_matrix(y_test_bin, predicted_test_y), \"\\n\")  \n",
        "\n",
        "# Imprimindo o relatório de classificação\n",
        "print(\"Relatório de classificação Decision Tree: \\n\", classification_report(y_test_bin, predicted_test_y, target_names=labels)) \n",
        "\n",
        "# Imprimindo a acurácia do modelo\n",
        "accuracy_dt = accuracy_score(y_test_bin, predicted_test_y) * 100\n",
        "print(\"Acurácia Decision Tree(Holdout): {:.2f}%.\".format(accuracy_dt))\n",
        "\n",
        "# Validação cruzada com k-fold e k=10\n",
        "scores_dt = cross_val_score(modeldt, X_test, y_test_bin, cv=10, scoring='accuracy')\n",
        "print(\"Acurácia média Decision Tree(k-fold): {:.2f}% e desvio padrão\".format(scores_dt.mean()*100), scores_dt.std())"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Matriz Confusa Decision Tree: \n",
            "[[ 392    0   24    0    3    6   12]\n",
            " [   1  170    1    0    0    0    0]\n",
            " [  29    0  485    0   18    1    5]\n",
            " [   1    0    0 1056    1   17   95]\n",
            " [   5    0   10    6  595    0   20]\n",
            " [   7    0    0   23    0  617   22]\n",
            " [   6    0    4   96   14   22  728]] \n",
            "\n",
            "Relatório de classificação Decision Tree: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    Barbunya       0.89      0.90      0.89       437\n",
            "      Bombay       1.00      0.99      0.99       172\n",
            "        Cali       0.93      0.90      0.91       538\n",
            "    Dermason       0.89      0.90      0.90      1170\n",
            "       Horoz       0.94      0.94      0.94       636\n",
            "       Seker       0.93      0.92      0.93       669\n",
            "        Sira       0.83      0.84      0.83       870\n",
            "\n",
            "    accuracy                           0.90      4492\n",
            "   macro avg       0.92      0.91      0.91      4492\n",
            "weighted avg       0.90      0.90      0.90      4492\n",
            "\n",
            "Acurácia Decision Tree(Holdout): 90.00%.\n",
            "Acurácia média Decision Tree(k-fold): 88.82% e desvio padrão 0.007951517070135387\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWM5MLyt6p_x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1578b469-f37f-4eeb-9b67-dd18e8f4e112"
      },
      "source": [
        "# Aplicando a Random Forest\n",
        "\n",
        "# Instanciando o modelo\n",
        "rf = RandomForestClassifier(100, max_depth=13, random_state=42)\n",
        "rf.fit(X_train,y_train_bin)\n",
        "\n",
        "# Aplicando o modelo\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "\n",
        "# Imprimindo a matriz confusa\n",
        "print(\"Matriz Confusa Random Forest: \")\n",
        "print(confusion_matrix(y_test_bin, y_pred_rf), \"\\n\")  \n",
        "\n",
        "# Imprimindo o relatório de classificação\n",
        "print(\"Relatório de classificação Random Forest: \\n\", classification_report(y_test_bin, y_pred_rf, target_names=labels)) \n",
        "\n",
        "# Imprimindo a acurácia do modelo\n",
        "accuracy_rf = accuracy_score(y_test_bin, y_pred_rf) * 100\n",
        "print(\"Acurácia Random Forest(Holdout): {:.2f}%.\".format(accuracy_rf))\n",
        "\n",
        "# Validação cruzada com k-fold e k=10\n",
        "scores_rf = cross_val_score(rf, X_test, y_test_bin, cv=10, scoring='accuracy')\n",
        "print(\"Acurácia médiaRandom Forest(k-fold): {:.2f}% e desvio padrão\".format(scores_rf.mean()*100), scores_rf.std())"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Matriz Confusa Random Forest: \n",
            "[[ 396    0   24    0    1    4   12]\n",
            " [   2  170    0    0    0    0    0]\n",
            " [  19    0  497    0   14    1    7]\n",
            " [   0    0    0 1082    2   19   67]\n",
            " [   1    0    8    5  602    0   20]\n",
            " [   3    0    0   15    0  634   17]\n",
            " [   3    0    2   90    8   17  750]] \n",
            "\n",
            "Relatório de classificação Random Forest: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    Barbunya       0.93      0.91      0.92       437\n",
            "      Bombay       1.00      0.99      0.99       172\n",
            "        Cali       0.94      0.92      0.93       538\n",
            "    Dermason       0.91      0.92      0.92      1170\n",
            "       Horoz       0.96      0.95      0.95       636\n",
            "       Seker       0.94      0.95      0.94       669\n",
            "        Sira       0.86      0.86      0.86       870\n",
            "\n",
            "    accuracy                           0.92      4492\n",
            "   macro avg       0.93      0.93      0.93      4492\n",
            "weighted avg       0.92      0.92      0.92      4492\n",
            "\n",
            "Acurácia Random Forest(Holdout): 91.96%.\n",
            "Acurácia médiaRandom Forest(k-fold): 91.36% e desvio padrão 0.0074917248660223154\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwxVsj3h6p_y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "324eae91-4155-4151-bfa7-95e1d0a0b66e"
      },
      "source": [
        "# Aplicando a Rede Neural MLP\n",
        "\n",
        "# Vetorizar a classe resposta\n",
        "lb = LabelBinarizer()\n",
        "y_train_vet = lb.fit_transform(y_train)\n",
        "y_test_vet = lb.fit_transform(y_test)\n",
        " \n",
        "# Instanciado o modelo\n",
        "modelNN = Sequential()\n",
        "modelNN.add(Dense(90, input_dim=16, activation='relu'))\n",
        "modelNN.add(Dense(7, activation='softmax'))\n",
        "modelNN.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Realizando o treinamento\n",
        "modelNN.fit(X_train_norm, y_train_vet, batch_size=128, epochs=500, verbose=0, validation_data=(X_test_norm, y_test_vet))\n",
        "\n",
        "def model_NN_K():\n",
        "  # Instanciado o modelo\n",
        "  modelNN_K = Sequential()\n",
        "  modelNN_K.add(Dense(90, input_dim=16, activation='relu'))\n",
        "  modelNN_K.add(Dense(7, activation='softmax'))\n",
        "  modelNN_K.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  return modelNN_K\n",
        "\n",
        "# Cria o modelo K\n",
        "modelNN_K = KerasClassifier(build_fn=model_NN_K, nb_epoch=500, batch_size=128, verbose=0)\n",
        "\n",
        "# Realizando o treinamento K\n",
        "modelNN_K.fit(X_train_norm, y_train_vet, validation_data=(X_test_norm, y_test_vet))\n",
        "\n",
        "# Avalidando a Rede Neural \n",
        "predictions = modelNN.predict(X_test_norm, batch_size=128)\n",
        "\n",
        "# Imprimindo a matriz confusa\n",
        "print(\"Matriz Confusa Rede Neural MLP: \")\n",
        "print(confusion_matrix(y_test_vet.argmax(axis=1), predictions.argmax(axis=1)), \"\\n\")  \n",
        "\n",
        "# Imprimindo o relatório de classificação\n",
        "print(\"Relatório de classificação Rede Neural MLP: \\n\", classification_report(y_test_vet.argmax(axis=1), predictions.argmax(axis=1), target_names=labels, zero_division=0))\n",
        "\n",
        "# Imprimindo a acurácia do modelo\n",
        "accuracy_nn = accuracy_score(y_test_vet.argmax(axis=1), predictions.argmax(axis=1)) * 100\n",
        "print(\"Acurácia Rede Neural MLP(Holdout): {:.2f}%.\".format(accuracy_nn))\n",
        "\n",
        "# Validação cruzada com k-fold e k=10\n",
        "scores_nn = cross_val_score(modelNN_K, X_test_norm, y_test_vet.argmax(axis=1), cv=10, scoring='accuracy')\n",
        "print(\"Acurácia média Rede Neural MLP(k-fold): {:.2f}% e desvio padrão\".format(scores_nn.mean()*100), scores_nn.std())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Matriz Confusa Rede Neural MLP: \n",
            "[[ 403    0   17    0    2    3   12]\n",
            " [   0  172    0    0    0    0    0]\n",
            " [  18    0  504    0   10    1    5]\n",
            " [   0    0    0 1096    3   21   50]\n",
            " [   2    0    5    6  606    0   17]\n",
            " [   5    0    1   11    0  639   13]\n",
            " [   3    0    1   91   14   11  750]] \n",
            "\n",
            "Relatório de classificação Rede Neural MLP: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    Barbunya       0.94      0.92      0.93       437\n",
            "      Bombay       1.00      1.00      1.00       172\n",
            "        Cali       0.95      0.94      0.95       538\n",
            "    Dermason       0.91      0.94      0.92      1170\n",
            "       Horoz       0.95      0.95      0.95       636\n",
            "       Seker       0.95      0.96      0.95       669\n",
            "        Sira       0.89      0.86      0.87       870\n",
            "\n",
            "    accuracy                           0.93      4492\n",
            "   macro avg       0.94      0.94      0.94      4492\n",
            "weighted avg       0.93      0.93      0.93      4492\n",
            "\n",
            "Acurácia Rede Neural MLP(Holdout): 92.83%.\n",
            "Acurácia média Rede Neural MLP(k-fold): 68.28% e desvio padrão 0.04528912196299066\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luBuatyA6p_y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aef5f2c5-d4b5-4e71-efd8-ddf03d91a4df"
      },
      "source": [
        "# Ensamble de Redes Neurais\n",
        "\n",
        "# Função com o modelo\n",
        "def gera_modelo(X_tr, y_tr):\n",
        "  # Instanciado o modelo\n",
        "  model = Sequential()\n",
        "  model.add(Dense(90, input_dim=16, activation='relu'))\n",
        "  model.add(Dense(7, activation='softmax'))\n",
        "  \n",
        "  # Compilando o modelo\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "  # Treinando o modelo\n",
        "  model.fit(X_tr, y_tr, epochs=500, batch_size=128, verbose=0)\n",
        "\n",
        "  return model\n",
        "\n",
        "# Diretório para armazenar cada modelo gerado\n",
        "makedirs('modelos')\n",
        "\n",
        "# Treina e salva os modelos\n",
        "n_members = 5\n",
        "for i in range(n_members):\n",
        "\t#Treina o modelo\n",
        "\tmodel = gera_modelo(X_train_norm, y_train_vet)\n",
        "\t#Salva o modelo\n",
        "\tfilename = 'modelos/modelo_' + str(i + 1) + '.h5'\n",
        "\tmodel.save(filename)\n",
        "\tprint('>Salvo %s' % filename)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">Salvo modelos/modelo_1.h5\n",
            ">Salvo modelos/modelo_2.h5\n",
            ">Salvo modelos/modelo_3.h5\n",
            ">Salvo modelos/modelo_4.h5\n",
            ">Salvo modelos/modelo_5.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mFEMXMMXCTuR",
        "outputId": "a1ec5f3d-d8b3-4fba-9e75-2229494963fe"
      },
      "source": [
        "# Carregar os modelos salvos\n",
        "def carregar_modelos(n_models):\n",
        "\tall_models = list()\n",
        "\tfor i in range(n_models):\n",
        "\t\t# Define o nome do modelo\n",
        "\t\tfilename = 'modelos/modelo_' + str(i + 1) + '.h5'\n",
        "\t\t# Carrega o arquivo com o modelo\n",
        "\t\tmodel = load_model(filename)\n",
        "\t\t# Adicionar o modelo a uma lista\n",
        "\t\tall_models.append(model)\n",
        "\t\tprint('>Carregando %s' % filename)\n",
        "\treturn all_models\n",
        "\n",
        "# Carregar todos os modelos\n",
        "n_members = 5\n",
        "members = carregar_modelos(n_members)\n",
        "print('Total de modelos carregados: %d' % len(members))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">Carregando modelos/modelo_1.h5\n",
            ">Carregando modelos/modelo_2.h5\n",
            ">Carregando modelos/modelo_3.h5\n",
            ">Carregando modelos/modelo_4.h5\n",
            ">Carregando modelos/modelo_5.h5\n",
            "Total de modelos carregados: 5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nm4qpwfqDcCg",
        "outputId": "396cefd2-ba36-43ca-e2e4-40054eb5edf0"
      },
      "source": [
        "# Avaliando o desempenho individual\n",
        "i = 1\n",
        "for model in members:\n",
        "    _, acc = model.evaluate(X_test_norm, y_test_vet, verbose=0)\n",
        "    print('Acurácia modelo ' + str(i) + ': %.3f' % acc)\n",
        "    i = i + 1"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Acurácia modelo 1: 0.926\n",
            "Acurácia modelo 2: 0.925\n",
            "Acurácia modelo 3: 0.927\n",
            "Acurácia modelo 4: 0.926\n",
            "Acurácia modelo 5: 0.925\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2avjN-RjMvU"
      },
      "source": [
        "# Cria o modelo a partir dos modelos salvos e retorna um Ensemble\n",
        "def stacked_dataset(members, inputX):\n",
        "\tstackX = None\n",
        "\tfor model in members:\n",
        "\t\t# Avalia o modelo\n",
        "\t\tyhat = model.predict(inputX, verbose=0)\n",
        "\t\t# Armazena as predições [rows, members, probabilities]\n",
        "\t\tif stackX is None:\n",
        "\t\t\tstackX = yhat\n",
        "\t\telse:\n",
        "\t\t\tstackX = dstack((stackX, yhat))\n",
        "\t# Aglutina as prdições [rows, members x probabilities]\n",
        "\tstackX = stackX.reshape((stackX.shape[0], stackX.shape[1]*stackX.shape[2]))\n",
        "\treturn stackX\n",
        "\n",
        "# Treina um modelo com base nas saídas dos membros do ensamble\n",
        "def fit_stacked_model(members, inputX, inputy):\n",
        "\t# Cria um dataset usando o ensemble\n",
        "\tstackedX = stacked_dataset(members, inputX)\n",
        "\t# Treina o modelo\n",
        "\tmodel = LogisticRegression()\n",
        "\tmodel.fit(stackedX, inputy)\n",
        "\treturn model"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-M0hySXlNrK"
      },
      "source": [
        "# Treina o modelo stacked utilizando o Ensemble\n",
        "model = fit_stacked_model(members, X_test_norm, y_test_bin)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBmjPIAZmQSO"
      },
      "source": [
        "# Classifica utilizando modelo Stacked\n",
        "def stacked_prediction(members, model, inputX):\n",
        "\t# Cria um conjunto de dados usando o Ensemble\n",
        "\tstackedX = stacked_dataset(members, inputX)\n",
        "\t# Faz a prediçãow\n",
        "\tyhat = model.predict(stackedX)\n",
        "\treturn yhat"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIvZqsUwnPfi",
        "outputId": "3f8d5a99-3ac1-4630-978f-71308df2a0bf"
      },
      "source": [
        "# Avaliando a predição realizada pelo Ensemble\n",
        "yhat = stacked_prediction(members, model, X_test_norm)\n",
        "acc = accuracy_score(y_test_bin, yhat)\n",
        "acc = acc*100\n",
        "\n",
        "# Imprimindo a matriz confusa\n",
        "print(\"Matriz Confusa Ensamble de Redes Neurais: \")\n",
        "print(confusion_matrix(y_test_bin, yhat), \"\\n\")\n",
        "\n",
        "# Imprimindo o relatório de classificação\n",
        "print(\"Relatório de classificação Ensamble de Redes Neurais: \\n\", classification_report(y_test_bin, yhat, target_names=labels, zero_division=0))\n",
        "\n",
        "# Acurácia do modelo\n",
        "print('Acurácia do Ensamble de Redes Neurais(Holdout): {:.2f}%'.format(acc))\n",
        "\n",
        "# Validação cruzada com k-fold e k=10\n",
        "scores_en = cross_val_score(model, X_test_norm, y_test_bin, cv=10, scoring='accuracy')\n",
        "print(\"Acurácia média Ensamble de Redes Neurais(k-fold): {:.2f}% e desvio padrão\".format(scores_en.mean()*100), scores_en.std())"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Matriz Confusa Ensamble de Redes Neurais: \n",
            "[[ 401    0   20    0    2    3   11]\n",
            " [   0  172    0    0    0    0    0]\n",
            " [  18    0  505    0    9    1    5]\n",
            " [   0    0    0 1079    1   12   78]\n",
            " [   2    0    9    6  604    0   15]\n",
            " [   5    0    1   16    0  632   15]\n",
            " [   5    0    2   77   10    8  768]] \n",
            "\n",
            "Relatório de classificação Ensamble de Redes Neurais: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    Barbunya       0.93      0.92      0.92       437\n",
            "      Bombay       1.00      1.00      1.00       172\n",
            "        Cali       0.94      0.94      0.94       538\n",
            "    Dermason       0.92      0.92      0.92      1170\n",
            "       Horoz       0.96      0.95      0.96       636\n",
            "       Seker       0.96      0.94      0.95       669\n",
            "        Sira       0.86      0.88      0.87       870\n",
            "\n",
            "    accuracy                           0.93      4492\n",
            "   macro avg       0.94      0.94      0.94      4492\n",
            "weighted avg       0.93      0.93      0.93      4492\n",
            "\n",
            "Acurácia do Ensamble de Redes Neurais(Holdout): 92.63%\n",
            "Acurácia média Ensamble de Redes Neurais(k-fold): 92.30% e desvio padrão 0.005720070172797905\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ef-y7fLh6p_y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7631633-648b-454d-8382-92436981aece"
      },
      "source": [
        "#Ensamble heterogêneo\n",
        "\n",
        "rng = np.random.RandomState(42)\n",
        "\n",
        "# KNN\n",
        "classifier\n",
        "# Decision Tree\n",
        "modeldt\n",
        "# Randon Forest\n",
        "rf\n",
        "# Rede Neural MLP\n",
        "model\n",
        "\n",
        "# Pool de classificadores\n",
        "pool_classifiers = [classifier, modeldt, rf, modelNN_K]\n",
        "\n",
        "# Classificadores para votação\n",
        "voting_classifiers = [(\"knn\", classifier), (\"tree\", modeldt), (\"random forest\", rf), (\"perceptron\", model)]\n",
        "\n",
        "# Treinando o Classificador de votação\n",
        "model_voting = VotingClassifier(estimators=voting_classifiers).fit(X_train_norm, y_train_bin)\n",
        "\n",
        "# Treinando o meta classificador\n",
        "stacked_dt = StackedClassifier(pool_classifiers, random_state=rng, meta_classifier=DecisionTreeClassifier())\n",
        "\n",
        "# Treinando o Ensemble\n",
        "stacked_dt.fit(X_test_norm, y_test_bin)\n",
        "\n",
        "# Avaliando o Ensemble\n",
        "predicted = model_voting.predict(X_test_norm)\n",
        "\n",
        "# Imprimindo a matriz confusa\n",
        "print(\"Matriz Confusa Ensamble Heterogêneo: \")\n",
        "print(confusion_matrix(y_test_bin, predicted), \"\\n\")  \n",
        "\n",
        "# Imprimindo o relatório de classificação\n",
        "print(\"Relatório de classificação Ensamble Heterogêneo: \\n\", classification_report(y_test_bin, predicted, target_names=labels, zero_division=0))\n",
        "\n",
        "# Acurácia do modelo\n",
        "print('Acurácia do Ensamble Heterogêneo(Holdout): {:.2f}%'.format(model_voting.score(X_test_norm, y_test_bin)*100))\n",
        "\n",
        "# Validação cruzada com k-fold e k=10\n",
        "scores_en_et = cross_val_score(model_voting, X_test_norm, y_test_bin, cv=10, scoring='accuracy')\n",
        "print(\"Acurácia média Ensamble Heterogêneo(k-fold): {:.2f}% e desvio padrão\".format(scores_en_et.mean()*100), scores_en_et.std())"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Matriz Confusa Ensamble Heterogêneo: \n",
            "[[ 399    0   22    0    1    3   12]\n",
            " [   1  171    0    0    0    0    0]\n",
            " [  17    0  504    0   11    1    5]\n",
            " [   0    0    0 1089    1   18   62]\n",
            " [   2    0    8    6  607    0   13]\n",
            " [   6    0    0   12    0  633   18]\n",
            " [   3    0    2   94   14   13  744]] \n",
            "\n",
            "Relatório de classificação Ensamble Heterogêneo: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    Barbunya       0.93      0.91      0.92       437\n",
            "      Bombay       1.00      0.99      1.00       172\n",
            "        Cali       0.94      0.94      0.94       538\n",
            "    Dermason       0.91      0.93      0.92      1170\n",
            "       Horoz       0.96      0.95      0.96       636\n",
            "       Seker       0.95      0.95      0.95       669\n",
            "        Sira       0.87      0.86      0.86       870\n",
            "\n",
            "    accuracy                           0.92      4492\n",
            "   macro avg       0.94      0.93      0.93      4492\n",
            "weighted avg       0.92      0.92      0.92      4492\n",
            "\n",
            "Acurácia do Ensamble Heterogêneo(Holdout): 92.32%\n",
            "Acurácia média Ensamble Heterogêneo(k-fold): 91.96% e desvio padrão 0.007056618131492955\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}